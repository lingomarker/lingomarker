<!DOCTYPE html>
<html lang="en">
{{ template "head.html" . }}
{{ template "top_bar.html" . }}

<head>
  <style>
    body {
      font-family: sans-serif;
      margin: 0;
      padding: 0;
      display: flex;
      flex-direction: column;
      height: 100vh;
    }

    .content-area {
      display: flex;
      flex-direction: column;
      flex: 1;
      overflow-y: auto;
      padding: 20px;
      box-sizing: border-box;
    }

    .content-area h1 {
      margin-top: 0;
      font-size: 1.4em;
      text-align: center;
    }

    #podcast-info-container {
      max-height: 20vh;
      flex: 1;
      overflow-y: auto;
      padding: 10px;
      border: 1px solid #ccc;
      background-color: #f9f9f9;
    }

    #podcast-player {
      margin: 10px 0;
      width: 100%;
    }

    #transcript-container {
      flex: 4;
      height: auto;
      overflow-y: auto;
      border: 1px solid #eee;
      padding: 10px;
    }

    .transcript-segment {
      margin-bottom: 12px;
      padding: 8px;
      border-radius: 4px;
      cursor: pointer;
      transition: background-color 0.3s;
    }

    .transcript-segment:hover {
      background-color: #e6e6e6;
    }

    .transcript-segment.playing {
      background-color: #d0e0ff;
      /* Soft bluish highlight */
    }

    .transcript-segment .speaker {
      font-weight: bold;
      color: #333;
    }

    .transcript-segment .text {
      margin-top: 4px;
      line-height: 1.6;
    }

    .loading-message {
      text-align: center;
      padding: 20px;
      font-style: italic;
    }

    #podcast-meta h2 {
      margin-top: 0;
    }

    .bottom-bar {
      display: flex;
      padding: 10px;
      background-color: #f0f0f0;
      box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.1);
      /* Shadow on top */
      gap: 10px;
      align-items: center;
    }
  </style>
</head>

<body>
  <div class="content-area">
    <h1>Podcast Player</h1>
    <div id="podcast-info-container">
      <div id="podcast-meta">
        <h2>{{ .Podcast.Episode }}</h2>
        <p><strong>Producer:</strong> {{ .Podcast.Producer }} | <strong>Series:</strong> {{ .Podcast.Series }}</p>
        {{ if .Podcast.Description }}
        <p><em>{{ .Podcast.Description }}</em></p>
        {{ end }}
      </div>
    </div>
    <audio id="podcast-player" controls></audio>
    <div id="transcript-container">
      <p class="loading-message">Loading transcript...</p>
    </div>
  </div>

  <div class="bottom-bar">
    <p><a href="/podcasts">Podcast List</a></p>
    <p><a href="/review">Review</a></p>
  </div>

  <script>
    const podcastId = "{{ .PodcastID }}";
    const audioPlayer = document.getElementById('podcast-player');
    const transcriptContainer = document.getElementById('transcript-container');
    let transcriptData = [];
    let currentPlayingSegment = null;
    let lastHighlightedElement = null;
    let initialHashTarget = null; // To store the target from the URL hash

    // --- Helper to parse "HH:MM:SS" OR "MM:SS" to seconds ---
    // (parseTimestampToSeconds and getSegmentTimes functions remain as corrected in the previous step)
    function parseTimestampToSeconds(timeStr) {
      if (!timeStr) return 0;
      const parts = String(timeStr).trim().split(':');
      let seconds = 0;
      try {
        if (parts.length === 3) {
          seconds = parseInt(parts[0], 10) * 3600 + parseInt(parts[1], 10) * 60 + parseFloat(parts[2]);
        } else if (parts.length === 2) {
          seconds = parseInt(parts[0], 10) * 60 + parseFloat(parts[1]);
        } else if (parts.length === 1) {
          seconds = parseFloat(parts[0]);
        }
      } catch (e) {
        console.error("Error parsing time string:", timeStr, e);
        return 0;
      }
      return isNaN(seconds) ? 0 : seconds;
    }

    function getSegmentTimes(timestampStr) {
      const defaultTimes = { start: 0, end: Infinity };
      if (!timestampStr || typeof timestampStr !== 'string') return defaultTimes;
      const times = timestampStr.split('-');
      if (times.length === 0) return defaultTimes;
      const start = parseTimestampToSeconds(times[0]);
      let end = Infinity;
      if (times.length > 1 && times[1].trim() !== "") {
        end = parseTimestampToSeconds(times[1]);
      }
      if (isFinite(start) && isFinite(end) && end < start) {
        console.warn(`Timestamp parse warning: End time (${times[1]} -> ${end}s) is before start time (${times[0]} -> ${start}s). Setting end to start time.`);
        end = start;
      }
      if (isFinite(start) && start > 0 && end === 0 && times.length > 1) {
        console.warn(`Timestamp parse warning: End time parsed as 0 (${times[1]}) while start time (${times[0]}) is positive. Using Infinity for end time.`);
        end = Infinity;
      }
      return { start, end };
    }


    // --- Render Transcript ---
    function renderTranscript(segments) {
      transcriptContainer.innerHTML = '';
      segments.forEach((segment, index) => {
        const segmentDiv = document.createElement('div');
        segmentDiv.classList.add('transcript-segment');
        segmentDiv.dataset.index = index;
        const { start, end } = getSegmentTimes(segment.timestamp);
        segmentDiv.dataset.startTime = start;
        segmentDiv.dataset.endTime = end;
        segmentDiv.dataset.timestamp = segment.timestamp; // Keep original timestamp string

        const speakerSpan = document.createElement('span');
        speakerSpan.classList.add('speaker');
        speakerSpan.textContent = segment.speaker ? `${segment.speaker}:` : 'Unknown Speaker:';

        const textP = document.createElement('p');
        textP.classList.add('text');
        textP.textContent = segment.text;

        segmentDiv.appendChild(speakerSpan);
        segmentDiv.appendChild(textP);
        transcriptContainer.appendChild(segmentDiv);
      });

      // --- After rendering, try to scroll to and highlight the target segment ---
      if (initialHashTarget) {
        scrollToAndHighlightSegment(initialHashTarget);
        initialHashTarget = null; // Clear it after use
      }
    }

    // --- New function to handle deep linking and highlighting ---
    function scrollToAndHighlightSegment(targetTimestamp) {
      let targetSegmentElement = null;
      const segments = transcriptContainer.querySelectorAll('.transcript-segment');
      for (const segmentEl of segments) {
        if (segmentEl.dataset.timestamp === targetTimestamp) {
          targetSegmentElement = segmentEl;
          break;
        }
      }

      if (targetSegmentElement) {
        console.log("Found target segment for deep link:", targetSegmentElement);
        targetSegmentElement.scrollIntoView({ behavior: 'smooth', block: 'center' });

        // Brief highlight (different from 'playing' highlight)
        targetSegmentElement.style.transition = 'background-color 0.3s ease-out';
        targetSegmentElement.style.backgroundColor = '#ffe0b2'; // A distinct temporary highlight color (e.g., light orange)
        setTimeout(() => {
          // Remove temporary highlight, revert to normal or 'playing' if audio starts
          if (!targetSegmentElement.classList.contains('playing')) {
            targetSegmentElement.style.backgroundColor = ''; // Revert to default
          } else {
            targetSegmentElement.style.backgroundColor = ''; // It will get #d0e0ff from 'playing' class
            // Or directly set to the 'playing' color if needed, but class should handle it
          }
        }, 2000); // Highlight for 2 seconds

        // Optional: Set audio player's current time to this segment's start, but DO NOT auto-play
        // const startTime = parseFloat(targetSegmentElement.dataset.startTime);
        // if (!isNaN(startTime)) {
        //     audioPlayer.currentTime = startTime;
        // }
      } else {
        console.warn("Deep link target segment not found for timestamp:", targetTimestamp);
      }
    }


    // --- Fetch Play Data ---
    async function fetchPlayData() {
      // --- Check for URL Hash before fetching ---
      if (window.location.hash) {
        const hash = window.location.hash.substring(1); // Remove #
        const params = new URLSearchParams(hash);
        if (params.has('segment_timestamp')) {
          initialHashTarget = params.get('segment_timestamp');
          console.log("Initial hash target timestamp:", initialHashTarget);
        }
      }
      // --- End Check URL Hash ---

      try {
        const response = await fetch(`/api/podcasts/${podcastId}/play_data`);
        if (!response.ok) {
          const errData = await response.json().catch(() => ({}));
          throw new Error(errData.error || `Failed to load podcast data: ${response.status}`);
        }
        const data = await response.json();
        audioPlayer.src = data.audioSrc;
        transcriptData = data.transcript || [];
        if (transcriptData.length > 0) {
          renderTranscript(transcriptData); // This will now also try to handle initialHashTarget
        } else {
          transcriptContainer.innerHTML = '<p class="loading-message">No transcript available.</p>';
        }

      } catch (error) {
        console.error("Error fetching play data:", error);
        transcriptContainer.innerHTML = `<p class="loading-message" style="color: red;">Error: ${error.message}</p>`;
      }
    }

    // --- Audio-to-Text Sync (timeupdate event listener) ---
    audioPlayer.addEventListener('timeupdate', () => {
      const currentTime = audioPlayer.currentTime;
      let activeSegmentElement = null; // Changed variable name for clarity

      // Iterate over rendered segment elements
      const segmentElements = transcriptContainer.querySelectorAll('.transcript-segment');
      for (const segmentEl of segmentElements) {
        const startTime = parseFloat(segmentEl.dataset.startTime);
        const endTime = parseFloat(segmentEl.dataset.endTime);

        if (currentTime >= startTime && currentTime < endTime) {
          activeSegmentElement = segmentEl;
          break;
        }
      }

      if (lastHighlightedElement && lastHighlightedElement !== activeSegmentElement) {
        lastHighlightedElement.classList.remove('playing');
      }

      if (activeSegmentElement) {
        if (!activeSegmentElement.classList.contains('playing')) {
          activeSegmentElement.classList.add('playing');
          // Scroll into view only if it's not the one we just deep-linked to (to avoid jerky scroll)
          // or if it's significantly out of view.
          // For simplicity now, always scroll.
          activeSegmentElement.scrollIntoView({ behavior: 'smooth', block: 'center', inline: 'nearest' });
        }
        lastHighlightedElement = activeSegmentElement;
      } else if (lastHighlightedElement) { // No active segment, but there was one
        lastHighlightedElement.classList.remove('playing');
        lastHighlightedElement = null;
      }


      if (currentPlayingSegment) {
        const currentSegmentEndTime = parseFloat(currentPlayingSegment.dataset.endTime) + 0.5; // Add 0.5s of extra time
        if (currentTime >= currentSegmentEndTime) {
          audioPlayer.pause();
          if (lastHighlightedElement && currentPlayingSegment === lastHighlightedElement) {
            // Only remove 'playing' if it's the segment that was clicked and just finished
            lastHighlightedElement.classList.remove('playing');
          }
          currentPlayingSegment = null;
          // lastHighlightedElement = null; // Don't nullify if audio is still playing near another segment
        }
      }
    });

    // --- Text-to-Audio Sync (click event listener on transcriptContainer) ---
    transcriptContainer.addEventListener('click', (event) => {
      const segmentElement = event.target.closest('.transcript-segment');
      if (segmentElement) {
        const textParagraph = segmentElement.querySelector('p.text'); // Get the child paragraph with class 'text'

        // Check if text is selected within this specific paragraph
        const selection = window.getSelection();
        if (textParagraph && textParagraph.contains(event.target) && selection && !selection.isCollapsed) {
          // If text is selected within this paragraph and the click was on/within it,
          // do nothing (don't play audio).
          // console.log("Text selected within paragraph, preventing audio playback for this click.");
          return;
        }

        const startTime = parseFloat(segmentElement.dataset.startTime);
        if (!isNaN(startTime)) {
          audioPlayer.currentTime = startTime;
          audioPlayer.play();
          currentPlayingSegment = segmentElement;

          // Ensure only the clicked segment gets the 'playing' class immediately if needed,
          // 'timeupdate' will also handle it but this can make it more responsive.
          if (lastHighlightedElement) {
            lastHighlightedElement.classList.remove('playing');
          }
          segmentElement.classList.add('playing');
          lastHighlightedElement = segmentElement;
          // Scroll it into view
          segmentElement.scrollIntoView({ behavior: 'smooth', block: 'center', inline: 'nearest' });
        }
      }
    });

    // --- Initial Load ---
    fetchPlayData();
  </script>

  <!-- LingoMarker Library and Dependencies -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.21/lodash.min.js"></script>
  <script src="/static/js/lingomarker.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      if (window.LingoMarker) {
        window.LingoMarker.init();
      } else {
        console.error('LingoMarker library not loaded.');
      }
    });
  </script>
</body>

</html>